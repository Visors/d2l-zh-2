{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "notebookb947f7d714",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Visors/d2l-zh-2/blob/main/tensorflow/chapter_convolutional-modern/batch-norm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "id": "22f585e3-a2cd-412e-a659-dd095cca81f2",
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/Visors/d2l-zh-2/blob/main/tensorflow/chapter_convolutional-modern/batch_norm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "22f585e3-a2cd-412e-a659-dd095cca81f2"
      }
    },
    {
      "id": "5043d27c",
      "cell_type": "markdown",
      "source": [
        "# 批量规范化\n",
        ":label:`sec_batch_norm`\n",
        "\n",
        "训练深层神经网络是十分困难的，特别是在较短的时间内使他们收敛更加棘手。\n",
        "本节将介绍*批量规范化*（batch normalization） :cite:`Ioffe.Szegedy.2015`，这是一种流行且有效的技术，可持续加速深层网络的收敛速度。\n",
        "再结合在 :numref:`sec_resnet`中将介绍的残差块，批量规范化使得研究人员能够训练100层以上的网络。\n",
        "\n",
        "## 训练深层网络\n",
        "\n",
        "为什么需要批量规范化层呢？让我们来回顾一下训练神经网络时出现的一些实际挑战。\n",
        "\n",
        "首先，数据预处理的方式通常会对最终结果产生巨大影响。\n",
        "回想一下我们应用多层感知机来预测房价的例子（ :numref:`sec_kaggle_house`）。\n",
        "使用真实数据时，我们的第一步是标准化输入特征，使其平均值为0，方差为1。\n",
        "直观地说，这种标准化可以很好地与我们的优化器配合使用，因为它可以将参数的量级进行统一。\n",
        "\n",
        "第二，对于典型的多层感知机或卷积神经网络。当我们训练时，中间层中的变量（例如，多层感知机中的仿射变换输出）可能具有更广的变化范围：不论是沿着从输入到输出的层，跨同一层中的单元，或是随着时间的推移，模型参数的随着训练更新变幻莫测。\n",
        "批量规范化的发明者非正式地假设，这些变量分布中的这种偏移可能会阻碍网络的收敛。\n",
        "直观地说，我们可能会猜想，如果一个层的可变值是另一层的100倍，这可能需要对学习率进行补偿调整。\n",
        "\n",
        "第三，更深层的网络很复杂，容易过拟合。\n",
        "这意味着正则化变得更加重要。\n",
        "\n",
        "批量规范化应用于单个可选层（也可以应用到所有层），其原理如下：在每次训练迭代中，我们首先规范化输入，即通过减去其均值并除以其标准差，其中两者均基于当前小批量处理。\n",
        "接下来，我们应用比例系数和比例偏移。\n",
        "正是由于这个基于*批量*统计的*标准化*，才有了*批量规范化*的名称。\n",
        "\n",
        "请注意，如果我们尝试使用大小为1的小批量应用批量规范化，我们将无法学到任何东西。\n",
        "这是因为在减去均值之后，每个隐藏单元将为0。\n",
        "所以，只有使用足够大的小批量，批量规范化这种方法才是有效且稳定的。\n",
        "请注意，在应用批量规范化时，批量大小的选择可能比没有批量规范化时更重要。\n",
        "\n",
        "从形式上来说，用$\\mathbf{x} \\in \\mathcal{B}$表示一个来自小批量$\\mathcal{B}$的输入，批量规范化$\\mathrm{BN}$根据以下表达式转换$\\mathbf{x}$：<font color=gray size=2px>看上去变成了一个关于$Z$分数的线性变换。</font>\n",
        "\n",
        "$$\\mathrm{BN}(\\mathbf{x}) = \\boldsymbol{\\gamma} \\odot \\frac{\\mathbf{x} - \\hat{\\boldsymbol{\\mu}}_\\mathcal{B}}{\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}} + \\boldsymbol{\\beta}.$$\n",
        ":eqlabel:`eq_batchnorm`\n",
        "\n",
        "在 :eqref:`eq_batchnorm`中，$\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$是小批量$\\mathcal{B}$的样本均值，$\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}$是小批量$\\mathcal{B}$的样本标准差。\n",
        "应用标准化后，生成的小批量的平均值为0和单位方差为1。\n",
        "由于单位方差（与其他一些魔法数）是一个主观的选择，因此我们通常包含\n",
        "*拉伸参数*（scale）$\\boldsymbol{\\gamma}$和*偏移参数*（shift）$\\boldsymbol{\\beta}$，它们的形状与$\\mathbf{x}$相同。\n",
        "请注意，$\\boldsymbol{\\gamma}$和$\\boldsymbol{\\beta}$是需要与其他模型参数一起学习的参数。\n",
        "\n",
        "由于在训练过程中，中间层的变化幅度不能过于剧烈，而批量规范化将每一层主动居中，并将它们重新调整为给定的平均值和大小（通过$\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$和${\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}}$）。\n",
        "\n",
        "从形式上来看，我们计算出 :eqref:`eq_batchnorm`中的$\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$和${\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}}$，如下所示：\n",
        "\n",
        "$$\\begin{aligned} \\hat{\\boldsymbol{\\mu}}_\\mathcal{B} &= \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} \\mathbf{x},\\\\\n",
        "\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}^2 &= \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} (\\mathbf{x} - \\hat{\\boldsymbol{\\mu}}_{\\mathcal{B}})^2 + \\epsilon.\\end{aligned}$$\n",
        "\n",
        "请注意，<font color=red><u>我们在方差估计值中添加一个小的常量$\\epsilon > 0$，以确保我们永远不会尝试除以零，即使在经验方差估计值可能消失的情况下也是如此。估计值$\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$和${\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}}$通过使用平均值和方差的噪声（noise）估计来抵消缩放问题。\n",
        "乍看起来，这种噪声是一个问题，而事实上它是有益的。</u></font>\n",
        "\n",
        "事实证明，这是深度学习中一个反复出现的主题。\n",
        "由于尚未在理论上明确的原因，优化中的各种噪声源通常会导致更快的训练和较少的过拟合：这种变化似乎是正则化的一种形式。\n",
        "在一些初步研究中， :cite:`Teye.Azizpour.Smith.2018`和 :cite:`Luo.Wang.Shao.ea.2018`分别将批量规范化的性质与贝叶斯先验相关联。\n",
        "这些理论揭示了为什么批量规范化最适应$50 \\sim 100$范围中的中等批量大小的难题。\n",
        "\n",
        "另外，批量规范化层在”训练模式“（通过小批量统计数据规范化）和“预测模式”（通过数据集统计规范化）中的功能不同。\n",
        "在训练过程中，我们无法得知使用整个数据集来估计平均值和方差，所以只能根据每个小批次的平均值和方差不断训练模型。\n",
        "而在预测模式下，可以根据整个数据集精确计算批量规范化所需的平均值和方差。\n",
        "\n",
        "现在，我们了解一下批量规范化在实践中是如何工作的。\n",
        "\n",
        "## 批量规范化层\n",
        "\n",
        "回想一下，批量规范化和其他层之间的一个关键区别是，由于批量规范化在完整的小批量上运行，因此我们不能像以前在引入其他层时那样忽略批量大小。\n",
        "我们在下面讨论这两种情况：全连接层和卷积层，他们的批量规范化实现略有不同。\n",
        "\n",
        "### 全连接层\n",
        "\n",
        "通常，我们将批量规范化层置于全连接层中的仿射变换和激活函数之间。\n",
        "设全连接层的输入为x，权重参数和偏置参数分别为$\\mathbf{W}$和$\\mathbf{b}$，激活函数为$\\phi$，批量规范化的运算符为$\\mathrm{BN}$。\n",
        "那么，使用批量规范化的全连接层的输出的计算详情如下：\n",
        "\n",
        "$$\\mathbf{h} = \\phi(\\mathrm{BN}(\\mathbf{W}\\mathbf{x} + \\mathbf{b}) ).$$\n",
        "\n",
        "回想一下，均值和方差是在应用变换的\"相同\"小批量上计算的。\n",
        "\n",
        "### 卷积层\n",
        "\n",
        "同样，对于卷积层，我们可以在卷积层之后和非线性激活函数之前应用批量规范化。\n",
        "当卷积有多个输出通道时，我们需要对这些通道的“每个”输出执行批量规范化，每个通道都有自己的拉伸（scale）和偏移（shift）参数，这两个参数都是标量。\n",
        "假设我们的小批量包含$m$个样本，并且对于每个通道，卷积的输出具有高度$p$和宽度$q$。\n",
        "那么对于卷积层，我们在每个输出通道的$m \\cdot p \\cdot q$个元素上同时执行每个批量规范化。\n",
        "因此，在计算平均值和方差时，我们会收集所有空间位置的值，然后在给定通道内应用相同的均值和方差，以便在每个空间位置对值进行规范化。\n",
        "\n",
        "### 预测过程中的批量规范化\n",
        "\n",
        "正如我们前面提到的，批量规范化在训练模式和预测模式下的行为通常不同。\n",
        "首先，将训练好的模型用于预测时，我们不再需要样本均值中的噪声以及在微批次上估计每个小批次产生的样本方差了。\n",
        "其次，例如，我们可能需要使用我们的模型对逐个样本进行预测。\n",
        "一种常用的方法是通过移动平均估算整个训练数据集的样本均值和方差，并在预测时使用它们得到确定的输出。\n",
        "可见，和暂退法一样，批量规范化层在训练模式和预测模式下的计算结果也是不一样的。\n",
        "\n",
        "## (**从零实现**)\n",
        "\n",
        "下面，我们从头开始实现一个具有张量的批量规范化层。\n"
      ],
      "metadata": {
        "origin_pos": 0,
        "id": "5043d27c"
      }
    },
    {
      "id": "c6b01140-3d59-4cd5-82b6-027fb2ce86ec",
      "cell_type": "code",
      "source": [
        "!pip install d2l"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T01:04:16.381414Z",
          "iopub.execute_input": "2025-03-04T01:04:16.381592Z",
          "iopub.status.idle": "2025-03-04T01:04:49.729035Z",
          "shell.execute_reply.started": "2025-03-04T01:04:16.381574Z",
          "shell.execute_reply": "2025-03-04T01:04:49.728182Z"
        },
        "id": "c6b01140-3d59-4cd5-82b6-027fb2ce86ec",
        "outputId": "985fc2da-ba36-4b22-9911-baccae5a18c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting d2l\n  Downloading d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\nCollecting jupyter==1.0.0 (from d2l)\n  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\nCollecting numpy==1.23.5 (from d2l)\n  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\nCollecting matplotlib==3.7.2 (from d2l)\n  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nCollecting matplotlib-inline==0.1.6 (from d2l)\n  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\nCollecting requests==2.31.0 (from d2l)\n  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\nCollecting pandas==2.0.3 (from d2l)\n  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting scipy==1.10.1 (from d2l)\n  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.5.4)\nRequirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\nRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\nRequirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.4.5)\nRequirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (5.5.6)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (8.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (11.0.0)\nCollecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l)\n  Downloading pyparsing-3.0.9-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (2.9.0.post0)\nRequirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline==0.1.6->d2l) (5.7.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l) (2025.1)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l) (1.17.0)\nRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (0.2.0)\nRequirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.34.0)\nRequirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (8.6.3)\nRequirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.3.3)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.2)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (4.0.13)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.13)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.48)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.19.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\nRequirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.4)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3.0)\nRequirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.7.2)\nRequirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.10.4)\nRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (6.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.1)\nRequirement already satisfied: testpath in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.6.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.12.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.0.2)\nRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (24.0.1)\nRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.1.0)\nRequirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.6.0)\nRequirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.18.1)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.21.1)\nRequirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.1.0)\nRequirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.4.3)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (75.1.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.9.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbconvert->jupyter==1.0.0->d2l) (4.3.6)\nRequirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.2.4)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (2.21.1)\nRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (4.23.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l) (0.2.13)\nRequirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.6)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.4)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (25.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (0.22.3)\nRequirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (2.12.5)\nRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.22)\nRequirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (3.7.1)\nRequirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.12.0)\nRequirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.5.3)\nRequirement already satisfied: overrides in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (7.7.0)\nRequirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.8.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.2.2)\nRequirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (3.2.1)\nRequirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (6.0.2)\nRequirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.1.1)\nRequirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.5.1)\nRequirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (3.0.0)\nRequirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.0)\nRequirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (24.11.1)\nRequirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (2.9.0.20241206)\nDownloading d2l-1.0.3-py3-none-any.whl (111 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\nDownloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\nDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: requests, pyparsing, numpy, matplotlib-inline, scipy, pandas, matplotlib, jupyter, d2l\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.3\n    Uninstalling requests-2.32.3:\n      Successfully uninstalled requests-2.32.3\n  Attempting uninstall: pyparsing\n    Found existing installation: pyparsing 3.2.0\n    Uninstalling pyparsing-3.2.0:\n      Successfully uninstalled pyparsing-3.2.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: matplotlib-inline\n    Found existing installation: matplotlib-inline 0.1.7\n    Uninstalling matplotlib-inline-0.1.7:\n      Successfully uninstalled matplotlib-inline-0.1.7\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.13.1\n    Uninstalling scipy-1.13.1:\n      Successfully uninstalled scipy-1.13.1\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.3\n    Uninstalling pandas-2.2.3:\n      Successfully uninstalled pandas-2.2.3\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.5\n    Uninstalling matplotlib-3.7.5:\n      Successfully uninstalled matplotlib-3.7.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nalbucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\nalbumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\nbayesian-optimization 2.0.3 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\nbigframes 1.29.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\nchex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\ndatasets 3.3.1 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ngoogle-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\njax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\njaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\nkaggle-environments 1.16.11 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\nlangchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\nmizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.5 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.5 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.23.5 which is incompatible.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nplotnine 0.14.4 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\npyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\npymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nscikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\nscikit-image 0.25.0 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nxarray 2024.11.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\nxarray 2024.11.0 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed d2l-1.0.3 jupyter-1.0.0 matplotlib-3.7.2 matplotlib-inline-0.1.6 numpy-1.23.5 pandas-2.0.3 pyparsing-3.0.9 requests-2.31.0 scipy-1.10.1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "id": "1638b920",
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l\n",
        "\n",
        "\n",
        "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps):\n",
        "    # 计算移动方差元平方根的倒数\n",
        "    inv = tf.cast(tf.math.rsqrt(moving_var + eps), X.dtype)\n",
        "    # 缩放和移位\n",
        "    inv *= gamma\n",
        "    Y = X * inv + (beta - moving_mean * inv)\n",
        "    return Y"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-04T01:05:06.919106Z",
          "iopub.execute_input": "2025-03-04T01:05:06.919394Z",
          "iopub.status.idle": "2025-03-04T01:05:18.38963Z",
          "shell.execute_reply.started": "2025-03-04T01:05:06.919371Z",
          "shell.execute_reply": "2025-03-04T01:05:18.388765Z"
        },
        "origin_pos": 3,
        "tab": [
          "tensorflow"
        ],
        "id": "1638b920",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "120cfdab",
      "cell_type": "markdown",
      "source": [
        "我们现在可以[**创建一个正确的`BatchNorm`层**]。\n",
        "这个层将保持适当的参数：拉伸`gamma`和偏移`beta`,这两个参数将在训练过程中更新。\n",
        "此外，我们的层将保存均值和方差的移动平均值，以便在模型预测期间随后使用。\n",
        "\n",
        "撇开算法细节，注意我们实现层的基础设计模式。\n",
        "通常情况下，我们用一个单独的函数定义其数学原理，比如说`batch_norm`。\n",
        "然后，我们将此功能集成到一个自定义层中，其代码主要处理数据移动到训练设备（如GPU）、分配和初始化任何必需的变量、跟踪移动平均线（此处为均值和方差）等问题。\n",
        "为了方便起见，我们并不担心在这里自动推断输入形状，因此我们需要指定整个特征的数量。\n",
        "不用担心，深度学习框架中的批量规范化API将为我们解决上述问题，我们稍后将展示这一点。\n"
      ],
      "metadata": {
        "origin_pos": 5,
        "id": "120cfdab"
      }
    },
    {
      "id": "e7fc2d13",
      "cell_type": "code",
      "source": [
        "class BatchNorm(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(BatchNorm, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        weight_shape = [input_shape[-1], ]\n",
        "        # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0\n",
        "        self.gamma = self.add_weight(name='gamma', shape=weight_shape,\n",
        "            initializer=tf.initializers.ones, trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=weight_shape,\n",
        "            initializer=tf.initializers.zeros, trainable=True)\n",
        "        # 非模型参数的变量初始化为0和1\n",
        "        self.moving_mean = self.add_weight(name='moving_mean',\n",
        "            shape=weight_shape, initializer=tf.initializers.zeros,\n",
        "            trainable=False)\n",
        "        self.moving_variance = self.add_weight(name='moving_variance',\n",
        "            shape=weight_shape, initializer=tf.initializers.ones,\n",
        "            trainable=False)\n",
        "        super(BatchNorm, self).build(input_shape)\n",
        "\n",
        "    def assign_moving_average(self, variable, value):\n",
        "        momentum = 0.9\n",
        "        delta = variable * momentum + value * (1 - momentum)\n",
        "        return variable.assign(delta)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs, training=True):\n",
        "        if training:\n",
        "            axes = list(range(len(inputs.shape) - 1))\n",
        "            batch_mean = tf.reduce_mean(inputs, axes, keepdims=True)\n",
        "            batch_variance = tf.reduce_mean(tf.math.squared_difference(\n",
        "                inputs, tf.stop_gradient(batch_mean)), axes, keepdims=True)\n",
        "            batch_mean = tf.squeeze(batch_mean, axes)\n",
        "            batch_variance = tf.squeeze(batch_variance, axes)\n",
        "            mean_update = self.assign_moving_average(\n",
        "                self.moving_mean, batch_mean)\n",
        "            variance_update = self.assign_moving_average(\n",
        "                self.moving_variance, batch_variance)\n",
        "            # self.add_update(mean_update)\n",
        "            # self.add_update(variance_update)\n",
        "            # 该方法已经 deprecated 了\n",
        "            mean, variance = batch_mean, batch_variance\n",
        "        else:\n",
        "            mean, variance = self.moving_mean, self.moving_variance\n",
        "        output = batch_norm(inputs, moving_mean=mean, moving_var=variance,\n",
        "            beta=self.beta, gamma=self.gamma, eps=1e-5)\n",
        "        return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-04T01:45:26.461039Z",
          "iopub.execute_input": "2025-03-04T01:45:26.461363Z",
          "iopub.status.idle": "2025-03-04T01:45:26.47007Z",
          "shell.execute_reply.started": "2025-03-04T01:45:26.461337Z",
          "shell.execute_reply": "2025-03-04T01:45:26.469191Z"
        },
        "origin_pos": 8,
        "tab": [
          "tensorflow"
        ],
        "id": "e7fc2d13",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "64a78eea",
      "cell_type": "markdown",
      "source": [
        "##  使用批量规范化层的 LeNet\n",
        "\n",
        "为了更好理解如何[**应用`BatchNorm`**]，下面我们将其应用(**于LeNet模型**)（ :numref:`sec_lenet`）。\n",
        "回想一下，批量规范化是在卷积层或全连接层之后、相应的激活函数之前应用的。\n"
      ],
      "metadata": {
        "origin_pos": 10,
        "id": "64a78eea"
      }
    },
    {
      "id": "c0dd746b",
      "cell_type": "code",
      "source": [
        "# 回想一下，这个函数必须传递给d2l.train_ch6。\n",
        "# 或者说为了利用我们现有的CPU/GPU设备，需要在strategy.scope()建立模型\n",
        "def net():\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=6, kernel_size=5,\n",
        "                               input_shape=(28, 28, 1)),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
        "        tf.keras.layers.Conv2D(filters=16, kernel_size=5),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(120),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.Dense(84),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.Dense(10)]\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-04T01:42:30.021171Z",
          "iopub.execute_input": "2025-03-04T01:42:30.021464Z",
          "iopub.status.idle": "2025-03-04T01:42:30.027068Z",
          "shell.execute_reply.started": "2025-03-04T01:42:30.021439Z",
          "shell.execute_reply": "2025-03-04T01:42:30.026144Z"
        },
        "origin_pos": 13,
        "tab": [
          "tensorflow"
        ],
        "id": "c0dd746b",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "68fb84e7",
      "cell_type": "markdown",
      "source": [
        "和以前一样，我们将[**在Fashion-MNIST数据集上训练网络**]。\n",
        "这个代码与我们第一次训练LeNet（ :numref:`sec_lenet`）时几乎完全相同，主要区别在于学习率大得多。\n"
      ],
      "metadata": {
        "origin_pos": 15,
        "id": "68fb84e7"
      }
    },
    {
      "id": "6b0fa6f0",
      "cell_type": "code",
      "source": [
        "lr, num_epochs, batch_size = 1.0, 10, 256\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
        "net = d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-04T01:42:32.688803Z",
          "iopub.execute_input": "2025-03-04T01:42:32.689102Z",
          "iopub.status.idle": "2025-03-04T01:42:57.614292Z",
          "shell.execute_reply.started": "2025-03-04T01:42:32.689079Z",
          "shell.execute_reply": "2025-03-04T01:42:57.613355Z"
        },
        "origin_pos": 17,
        "tab": [
          "tensorflow"
        ],
        "id": "6b0fa6f0",
        "outputId": "c3347790-c044-4074-db58-d085144e6acb",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "loss 0.279, train acc 0.896, test acc 0.846\n32284.2 examples/sec on /GPU:0\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 350x250 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-03-04T01:42:57.576179</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.5, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 51.803125 145.8 \nL 51.803125 7.2 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"m7f70752f85\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m7f70752f85\" x=\"51.803125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2 -->\n      <g transform=\"translate(48.621875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 95.203125 145.8 \nL 95.203125 7.2 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m7f70752f85\" x=\"95.203125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 4 -->\n      <g transform=\"translate(92.021875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 138.603125 145.8 \nL 138.603125 7.2 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m7f70752f85\" x=\"138.603125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 6 -->\n      <g transform=\"translate(135.421875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 182.003125 145.8 \nL 182.003125 7.2 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m7f70752f85\" x=\"182.003125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 8 -->\n      <g transform=\"translate(178.821875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m7f70752f85\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path d=\"M 30.103125 114.843096 \nL 225.403125 114.843096 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path id=\"mb87847905e\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mb87847905e\" x=\"30.103125\" y=\"114.843096\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 118.642315) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path d=\"M 30.103125 73.956964 \nL 225.403125 73.956964 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#mb87847905e\" x=\"30.103125\" y=\"73.956964\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 77.756183) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path d=\"M 30.103125 33.070833 \nL 225.403125 33.070833 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#mb87847905e\" x=\"30.103125\" y=\"33.070833\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 36.870052) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 30.103125 41.138128 \nL 51.803125 93.978721 \nL 73.503125 108.937773 \nL 95.203125 117.890689 \nL 116.903125 124.814076 \nL 138.603125 128.71333 \nL 160.303125 131.799782 \nL 182.003125 135.167678 \nL 203.703125 137.34787 \nL 225.403125 139.5 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 30.103125 48.362247 \nL 51.803125 29.765876 \nL 73.503125 24.300762 \nL 95.203125 21.132085 \nL 116.903125 18.70617 \nL 138.603125 17.339889 \nL 160.303125 16.154201 \nL 182.003125 14.818577 \nL 203.703125 14.075815 \nL 225.403125 13.5 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 30.103125 40.982294 \nL 51.803125 26.794816 \nL 73.503125 34.399631 \nL 95.203125 26.488168 \nL 116.903125 22.624421 \nL 138.603125 24.218989 \nL 160.303125 18.474484 \nL 182.003125 24.586964 \nL 203.703125 24.341643 \nL 225.403125 23.585246 \n\" clip-path=\"url(#p37a37926e7)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 140.634375 100.017188 \nL 218.403125 100.017188 \nQ 220.403125 100.017188 220.403125 98.017188 \nL 220.403125 54.982812 \nQ 220.403125 52.982812 218.403125 52.982812 \nL 140.634375 52.982812 \nQ 138.634375 52.982812 138.634375 54.982812 \nL 138.634375 98.017188 \nQ 138.634375 100.017188 140.634375 100.017188 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 142.634375 61.08125 \nL 152.634375 61.08125 \nL 162.634375 61.08125 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_10\">\n     <!-- train loss -->\n     <g transform=\"translate(170.634375 64.58125) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n     </g>\n    </g>\n    <g id=\"line2d_21\">\n     <path d=\"M 142.634375 75.759375 \nL 152.634375 75.759375 \nL 162.634375 75.759375 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- train acc -->\n     <g transform=\"translate(170.634375 79.259375) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 142.634375 90.4375 \nL 152.634375 90.4375 \nL 162.634375 90.4375 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- test acc -->\n     <g transform=\"translate(170.634375 93.9375) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"100.732422\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"152.832031\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"192.041016\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"223.828125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"285.107422\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"340.087891\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p37a37926e7\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "id": "78f8e4ac",
      "cell_type": "markdown",
      "source": [
        "让我们来看看从第一个批量规范化层中学到的[**拉伸参数`gamma`和偏移参数`beta`**]。\n"
      ],
      "metadata": {
        "origin_pos": 18,
        "id": "78f8e4ac"
      }
    },
    {
      "id": "557a9333",
      "cell_type": "code",
      "source": [
        "tf.reshape(net.layers[1].gamma, (-1,)), tf.reshape(net.layers[1].beta, (-1,))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-04T01:43:40.328621Z",
          "iopub.execute_input": "2025-03-04T01:43:40.328947Z",
          "iopub.status.idle": "2025-03-04T01:43:40.338345Z",
          "shell.execute_reply.started": "2025-03-04T01:43:40.328921Z",
          "shell.execute_reply": "2025-03-04T01:43:40.337604Z"
        },
        "origin_pos": 21,
        "tab": [
          "tensorflow"
        ],
        "id": "557a9333",
        "outputId": "eeb7213f-69b1-41a7-cce2-e21026670e3a",
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(<tf.Tensor: shape=(6,), dtype=float32, numpy=\n array([4.1323123 , 4.050942  , 0.62983704, 0.2560904 , 2.409042  ,\n        1.9074546 ], dtype=float32)>,\n <tf.Tensor: shape=(6,), dtype=float32, numpy=\n array([-4.3410416 ,  1.868698  ,  1.7092295 ,  0.11787247, -1.5056425 ,\n         2.1887484 ], dtype=float32)>)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "id": "27a46ec6",
      "cell_type": "markdown",
      "source": [
        "## [**简明实现**]\n",
        "\n",
        "除了使用我们刚刚定义的`BatchNorm`，我们也可以直接使用深度学习框架中定义的`BatchNorm`。\n",
        "该代码看起来几乎与我们上面的代码相同。\n"
      ],
      "metadata": {
        "origin_pos": 23,
        "id": "27a46ec6"
      }
    },
    {
      "id": "e1f38c12",
      "cell_type": "code",
      "source": [
        "def net():\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=6, kernel_size=5,\n",
        "                               input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
        "        tf.keras.layers.Conv2D(filters=16, kernel_size=5),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(120),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.Dense(84),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.Dense(10),\n",
        "    ])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-04T01:43:43.994201Z",
          "iopub.execute_input": "2025-03-04T01:43:43.99449Z",
          "iopub.status.idle": "2025-03-04T01:43:44.00004Z",
          "shell.execute_reply.started": "2025-03-04T01:43:43.994469Z",
          "shell.execute_reply": "2025-03-04T01:43:43.999144Z"
        },
        "origin_pos": 26,
        "tab": [
          "tensorflow"
        ],
        "id": "e1f38c12",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d638bf58",
      "cell_type": "markdown",
      "source": [
        "下面，我们[**使用相同超参数来训练模型**]。\n",
        "请注意，通常高级API变体运行速度快得多，因为它的代码已编译为C++或CUDA，而我们的自定义代码由Python实现。\n"
      ],
      "metadata": {
        "origin_pos": 28,
        "id": "d638bf58"
      }
    },
    {
      "id": "45d11203",
      "cell_type": "code",
      "source": [
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-04T01:43:47.715268Z",
          "iopub.execute_input": "2025-03-04T01:43:47.715548Z",
          "iopub.status.idle": "2025-03-04T01:44:09.036576Z",
          "shell.execute_reply.started": "2025-03-04T01:43:47.715528Z",
          "shell.execute_reply": "2025-03-04T01:44:09.035723Z"
        },
        "origin_pos": 29,
        "tab": [
          "tensorflow"
        ],
        "id": "45d11203",
        "outputId": "2667dfd9-6cd5-44dc-eb1d-28bcd9364161",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "loss 0.271, train acc 0.899, test acc 0.876\n36735.6 examples/sec on /GPU:0\n",
          "output_type": "stream"
        },
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<Sequential name=sequential_8, built=True>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 350x250 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-03-04T01:44:08.996475</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.5, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 51.803125 145.8 \nL 51.803125 7.2 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"madf3a793ce\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#madf3a793ce\" x=\"51.803125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2 -->\n      <g transform=\"translate(48.621875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 95.203125 145.8 \nL 95.203125 7.2 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#madf3a793ce\" x=\"95.203125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 4 -->\n      <g transform=\"translate(92.021875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 138.603125 145.8 \nL 138.603125 7.2 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#madf3a793ce\" x=\"138.603125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 6 -->\n      <g transform=\"translate(135.421875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 182.003125 145.8 \nL 182.003125 7.2 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#madf3a793ce\" x=\"182.003125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 8 -->\n      <g transform=\"translate(178.821875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#madf3a793ce\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path d=\"M 30.103125 113.669785 \nL 225.403125 113.669785 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path id=\"mabb436c8d9\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mabb436c8d9\" x=\"30.103125\" y=\"113.669785\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 117.469004) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path d=\"M 30.103125 73.544359 \nL 225.403125 73.544359 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#mabb436c8d9\" x=\"30.103125\" y=\"73.544359\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 77.343578) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path d=\"M 30.103125 33.418933 \nL 225.403125 33.418933 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#mabb436c8d9\" x=\"30.103125\" y=\"33.418933\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 37.218152) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 30.103125 45.574157 \nL 51.803125 98.155188 \nL 73.503125 112.293329 \nL 95.203125 120.687242 \nL 116.903125 126.022466 \nL 138.603125 129.17809 \nL 160.303125 132.347897 \nL 182.003125 135.072364 \nL 203.703125 137.22437 \nL 225.403125 139.5 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 30.103125 46.499826 \nL 51.803125 28.282873 \nL 73.503125 23.066575 \nL 95.203125 19.930102 \nL 116.903125 18.241493 \nL 138.603125 17.121323 \nL 160.303125 15.937618 \nL 182.003125 14.87096 \nL 203.703125 14.325913 \nL 225.403125 13.5 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 30.103125 90.055969 \nL 51.803125 40.902321 \nL 73.503125 26.938676 \nL 95.203125 23.748701 \nL 116.903125 23.046509 \nL 138.603125 23.166882 \nL 160.303125 20.538673 \nL 182.003125 21.441489 \nL 203.703125 16.185059 \nL 225.403125 18.091022 \n\" clip-path=\"url(#p836e1a3f4b)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 140.634375 100.017188 \nL 218.403125 100.017188 \nQ 220.403125 100.017188 220.403125 98.017188 \nL 220.403125 54.982812 \nQ 220.403125 52.982812 218.403125 52.982812 \nL 140.634375 52.982812 \nQ 138.634375 52.982812 138.634375 54.982812 \nL 138.634375 98.017188 \nQ 138.634375 100.017188 140.634375 100.017188 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 142.634375 61.08125 \nL 152.634375 61.08125 \nL 162.634375 61.08125 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_10\">\n     <!-- train loss -->\n     <g transform=\"translate(170.634375 64.58125) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n     </g>\n    </g>\n    <g id=\"line2d_21\">\n     <path d=\"M 142.634375 75.759375 \nL 152.634375 75.759375 \nL 162.634375 75.759375 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- train acc -->\n     <g transform=\"translate(170.634375 79.259375) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 142.634375 90.4375 \nL 152.634375 90.4375 \nL 162.634375 90.4375 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- test acc -->\n     <g transform=\"translate(170.634375 93.9375) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"100.732422\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"152.832031\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"192.041016\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"223.828125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"285.107422\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"340.087891\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p836e1a3f4b\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "id": "8bec8e68",
      "cell_type": "markdown",
      "source": [
        "## 争议\n",
        "\n",
        "直观地说，批量规范化被认为可以使优化更加平滑。\n",
        "然而，我们必须小心区分直觉和对我们观察到的现象的真实解释。\n",
        "回想一下，我们甚至不知道简单的神经网络（多层感知机和传统的卷积神经网络）为什么如此有效。\n",
        "即使在暂退法和权重衰减的情况下，它们仍然非常灵活，因此无法通过常规的学习理论泛化保证来解释它们是否能够泛化到看不见的数据。\n",
        "\n",
        "在提出批量规范化的论文中，作者除了介绍了其应用，还解释了其原理：通过减少*内部协变量偏移*（internal covariate shift）。\n",
        "据推测，作者所说的*内部协变量转移*类似于上述的投机直觉，即变量值的分布在训练过程中会发生变化。\n",
        "然而，这种解释有两个问题：\n",
        "1、这种偏移与严格定义的*协变量偏移*（covariate shift）非常不同，所以这个名字用词不当；\n",
        "2、这种解释只提供了一种不明确的直觉，但留下了一个有待后续挖掘的问题：为什么这项技术如此有效？\n",
        "本书旨在传达实践者用来发展深层神经网络的直觉。\n",
        "然而，重要的是将这些指导性直觉与既定的科学事实区分开来。\n",
        "最终，当你掌握了这些方法，并开始撰写自己的研究论文时，你会希望清楚地区分技术和直觉。\n",
        "\n",
        "随着批量规范化的普及，*内部协变量偏移*的解释反复出现在技术文献的辩论，特别是关于“如何展示机器学习研究”的更广泛的讨论中。\n",
        "Ali Rahimi在接受2017年NeurIPS大会的“接受时间考验奖”（Test of Time Award）时发表了一篇令人难忘的演讲。他将“内部协变量转移”作为焦点，将现代深度学习的实践比作炼金术。\n",
        "他对该示例进行了详细回顾 :cite:`Lipton.Steinhardt.2018`，概述了机器学习中令人不安的趋势。\n",
        "此外，一些作者对批量规范化的成功提出了另一种解释：在某些方面，批量规范化的表现出与原始论文 :cite:`Santurkar.Tsipras.Ilyas.ea.2018`中声称的行为是相反的。\n",
        "\n",
        "然而，与机器学习文献中成千上万类似模糊的说法相比，内部协变量偏移没有更值得批评。\n",
        "很可能，它作为这些辩论的焦点而产生共鸣，要归功于目标受众对它的广泛认可。\n",
        "批量规范化已经被证明是一种不可或缺的方法。它适用于几乎所有图像分类器，并在学术界获得了数万引用。\n",
        "\n",
        "## 小结\n",
        "\n",
        "* 在模型训练过程中，批量规范化利用小批量的均值和标准差，不断调整神经网络的中间输出，使整个神经网络各层的中间输出值更加稳定。\n",
        "* 批量规范化在全连接层和卷积层的使用略有不同。\n",
        "* 批量规范化层和暂退层一样，在训练模式和预测模式下计算不同。\n",
        "* 批量规范化有许多有益的副作用，主要是正则化。另一方面，”减少内部协变量偏移“的原始动机似乎不是一个有效的解释。\n",
        "\n",
        "## 练习\n",
        "\n",
        "1. 在使用批量规范化之前，我们是否可以从全连接层或卷积层中删除偏置参数？为什么？\n",
        "1. 比较LeNet在使用和不使用批量规范化情况下的学习率。\n",
        "    1. 绘制训练和测试准确度的提高。\n",
        "    1. 学习率有多高？\n",
        "1. 我们是否需要在每个层中进行批量规范化？尝试一下？\n",
        "1. 可以通过批量规范化来替换暂退法吗？行为会如何改变？\n",
        "1. 确定参数`beta`和`gamma`，并观察和分析结果。\n",
        "1. 查看高级API中有关`BatchNorm`的在线文档，以查看其他批量规范化的应用。\n",
        "1. 研究思路：可以应用的其他“规范化”转换？可以应用概率积分变换吗？全秩协方差估计可以么？\n"
      ],
      "metadata": {
        "origin_pos": 30,
        "id": "8bec8e68"
      }
    },
    {
      "id": "75ceb09a",
      "cell_type": "markdown",
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/1875)\n"
      ],
      "metadata": {
        "origin_pos": 33,
        "tab": [
          "tensorflow"
        ],
        "id": "75ceb09a"
      }
    }
  ]
}