{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Visors/d2l-zh-2/blob/main/tensorflow/chapter_deep-learning-computation/custom-layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d86768b",
      "metadata": {
        "origin_pos": 0,
        "id": "3d86768b"
      },
      "source": [
        "# 自定义层\n",
        "\n",
        "深度学习成功背后的一个因素是神经网络的灵活性：\n",
        "我们可以用创造性的方式组合不同的层，从而设计出适用于各种任务的架构。\n",
        "例如，研究人员发明了专门用于处理图像、文本、序列数据和执行动态规划的层。\n",
        "有时我们会遇到或要自己发明一个现在在深度学习框架中还不存在的层。\n",
        "在这些情况下，必须构建自定义层。本节将展示如何构建自定义层。\n",
        "\n",
        "## 不带参数的层\n",
        "\n",
        "首先，我们(**构造一个没有任何参数的自定义层**)。\n",
        "回忆一下在 :numref:`sec_model_construction`对块的介绍，\n",
        "这应该看起来很眼熟。\n",
        "下面的`CenteredLayer`类要从其输入中减去均值。\n",
        "要构建它，我们只需继承基础层类并实现前向传播功能。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "971dcce8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:27:01.181747Z",
          "iopub.status.busy": "2023-08-18T07:27:01.181052Z",
          "iopub.status.idle": "2023-08-18T07:27:03.453804Z",
          "shell.execute_reply": "2023-08-18T07:27:03.452572Z"
        },
        "origin_pos": 3,
        "tab": [
          "tensorflow"
        ],
        "id": "971dcce8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class CenteredLayer(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs - tf.reduce_mean(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48728853",
      "metadata": {
        "origin_pos": 5,
        "id": "48728853"
      },
      "source": [
        "让我们向该层提供一些数据，验证它是否能按预期工作。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e5520aee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:27:03.459667Z",
          "iopub.status.busy": "2023-08-18T07:27:03.459197Z",
          "iopub.status.idle": "2023-08-18T07:27:04.567785Z",
          "shell.execute_reply": "2023-08-18T07:27:04.566894Z"
        },
        "origin_pos": 8,
        "tab": [
          "tensorflow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5520aee",
        "outputId": "5e984b2e-6b48-46c1-cdcb-816d9f35eb18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([-2, -1,  0,  1,  2], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "layer = CenteredLayer()\n",
        "layer(tf.constant([1, 2, 3, 4, 5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fdbe0d4",
      "metadata": {
        "origin_pos": 10,
        "id": "9fdbe0d4"
      },
      "source": [
        "现在，我们可以[**将层作为组件合并到更复杂的模型中**]。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "89b301bd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:27:04.573542Z",
          "iopub.status.busy": "2023-08-18T07:27:04.572987Z",
          "iopub.status.idle": "2023-08-18T07:27:04.584568Z",
          "shell.execute_reply": "2023-08-18T07:27:04.583750Z"
        },
        "origin_pos": 13,
        "tab": [
          "tensorflow"
        ],
        "id": "89b301bd"
      },
      "outputs": [],
      "source": [
        "net = tf.keras.Sequential([tf.keras.layers.Dense(128), CenteredLayer()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "786e6370",
      "metadata": {
        "origin_pos": 14,
        "id": "786e6370"
      },
      "source": [
        "作为额外的健全性检查，我们可以在向该网络发送随机数据后，检查均值是否为0。\n",
        "由于我们处理的是浮点数，因为存储精度的原因，我们仍然可能会看到一个非常小的非零数。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a666497a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:27:04.589361Z",
          "iopub.status.busy": "2023-08-18T07:27:04.588817Z",
          "iopub.status.idle": "2023-08-18T07:27:04.656536Z",
          "shell.execute_reply": "2023-08-18T07:27:04.655732Z"
        },
        "origin_pos": 17,
        "tab": [
          "tensorflow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a666497a",
        "outputId": "7b4a1d29-c247-4b99-e3cf-aaa27f550ad4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-5.587935447692871e-09>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "Y = net(tf.random.uniform((4, 8)))\n",
        "tf.reduce_mean(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c32b28d1",
      "metadata": {
        "origin_pos": 19,
        "id": "c32b28d1"
      },
      "source": [
        "## [**带参数的层**]\n",
        "\n",
        "以上我们知道了如何定义简单的层，下面我们继续定义具有参数的层，\n",
        "这些参数可以通过训练进行调整。\n",
        "我们可以使用内置函数来创建参数，这些函数提供一些基本的管理功能。\n",
        "比如管理访问、初始化、共享、保存和加载模型参数。\n",
        "这样做的好处之一是：我们不需要为每个自定义层编写自定义的序列化程序。\n",
        "\n",
        "现在，让我们实现自定义版本的全连接层。\n",
        "回想一下，该层需要两个参数，一个用于表示权重，另一个用于表示偏置项。\n",
        "在此实现中，我们使用修正线性单元作为激活函数。\n",
        "该层需要输入参数：`in_units`和`units`，分别表示输入数和输出数。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3703a356",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:27:04.661428Z",
          "iopub.status.busy": "2023-08-18T07:27:04.660881Z",
          "iopub.status.idle": "2023-08-18T07:27:04.666635Z",
          "shell.execute_reply": "2023-08-18T07:27:04.665855Z"
        },
        "origin_pos": 22,
        "tab": [
          "tensorflow"
        ],
        "id": "3703a356"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MyDense(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    自定义的全连接层 (Dense Layer)\n",
        "\n",
        "    继承自 tf.keras.Model，用于创建具有权重和偏置的自定义层。\n",
        "    \"\"\"\n",
        "    def __init__(self, units):\n",
        "        \"\"\"\n",
        "        类的构造函数\n",
        "\n",
        "        Args:\n",
        "            units (int): 输出单元的数量，即该层的输出维度。\n",
        "        \"\"\"\n",
        "        super().__init__()  # 调用父类 tf.keras.Model 的构造函数\n",
        "        self.units = units  # 保存输出单元数量，作为该层的属性\n",
        "\n",
        "    def build(self, X_shape):\n",
        "        \"\"\"\n",
        "        构建层的权重和偏置\n",
        "\n",
        "        此方法在第一次调用 call 方法时自动调用，用以延迟初始化。\n",
        "        用于创建层的可训练参数。\n",
        "\n",
        "        Args:\n",
        "            X_shape (tuple): 输入张量的形状 (shape)。\n",
        "        \"\"\"\n",
        "        # 添加权重 (weight)\n",
        "        self.weight = self.add_weight(\n",
        "            name='weight',  # 参数名称\n",
        "            shape=[X_shape[-1], self.units],  # 权重矩阵的形状：[输入特征数, 输出单元数]\n",
        "            initializer=tf.random_normal_initializer()  # 使用正态分布初始化权重\n",
        "        )\n",
        "        # 添加偏置 (bias)\n",
        "        self.bias = self.add_weight(\n",
        "            name='bias',  # 参数名称\n",
        "            shape=[self.units],  # 偏置向量的形状：[输出单元数]\n",
        "            initializer=tf.zeros_initializer()  # 使用零初始化偏置\n",
        "        )\n",
        "\n",
        "    def call(self, X):\n",
        "        \"\"\"\n",
        "        定义层的前向传播逻辑\n",
        "\n",
        "        Args:\n",
        "            X (tf.Tensor): 输入张量。\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: 输出张量。\n",
        "        \"\"\"\n",
        "        linear = tf.matmul(X, self.weight) + self.bias  # 线性变换：矩阵乘法 + 偏置\n",
        "        return tf.nn.relu(linear)  # 应用 ReLU 激活函数"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`tf.keras.Model` 的自动构建机制：**（mio按）\n",
        "\n",
        "*   当你创建一个继承自 `tf.keras.Model` 的自定义层（例如 `MyDense`）时，你不需要手动去调用 `build` 方法。TensorFlow 会自动帮你完成这个过程。\n",
        "*   当你第一次用某个输入 `X` 调用这个自定义层的 `call` 方法时（例如 `dense(tf.random.uniform((2, 5)))`），TensorFlow 会做以下事情：\n",
        "    1.  **检查是否已构建：** 检查这个层是否已经调用过 `build` 方法创建了它的权重和偏置等参数。\n",
        "    2.  **未构建则调用 `build`：** 如果该层还没有构建过（即第一次调用），TensorFlow 会**自动**调用该层的 `build` 方法。\n",
        "    3.  **推断 `X_shape`：** 在调用 `build` 方法之前，TensorFlow 会分析你传入 `call` 方法的输入张量 `X` 的形状，即 `X.shape`。\n",
        "    4.  **传递 `X.shape` 给 `build`：**  TensorFlow 会把 `X.shape` 以某种形式（通常是 `tf.TensorShape` 对象）作为参数 `X_shape` 传递给 `build` 方法。这就是 `build` 方法中 `X_shape` 的来源。\n",
        "    5.  **`build` 创建参数：**  `build` 方法使用 `X_shape` 来确定需要创建的参数（例如权重矩阵）的形状，然后创建这些参数。\n",
        "    6. **调用`call`:** 创建参数之后再进行`call`的计算。"
      ],
      "metadata": {
        "id": "pv6VDMmCbNWx"
      },
      "id": "pv6VDMmCbNWx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**关键点：`tf.keras.Model` 内部的生命周期管理**\n",
        "\n",
        "`tf.keras.Model` 类（以及其基类 `tf.keras.layers.Layer`）内部实现了一个复杂的生命周期管理机制。这个机制的核心任务是：\n",
        "\n",
        "1.  **跟踪模型/层是否已经构建：** 判断模型/层的参数是否已经被创建（即 `build` 方法是否执行过）。\n",
        "2.  **在需要时自动触发构建：** 如果模型/层还没有构建，并且需要使用，则自动调用 `build` 方法。\n",
        "\n",
        "**详细解释自动执行 `build` 的过程：**\n",
        "\n",
        "1.  **`__call__` 方法：**\n",
        "    *   当你调用 `dense(tf.random.uniform((2, 5)))` 时，你实际上是在调用 `MyDense` 类（或者任何继承自 `tf.keras.Model` 的类的）的 `__call__` 方法。\n",
        "    *   请注意，是你定义的`call`函数被`__call__`所调用。`__call__`是一个特殊的函数，使得对象可以像函数一样被调用。例如：`dense(tf.random.uniform((2, 5)))`。\n",
        "    *   这个 `__call__` 方法是 `tf.keras.Model`（或 `tf.keras.layers.Layer`）中定义的，而不是你在 `MyDense` 类中定义的。\n",
        "    *   这个 `__call__` 方法是**关键所在**，因为它负责在真正执行你写的 `call` 方法之前，进行一些重要的检查和操作。\n",
        "\n",
        "2.  **`__call__` 方法内部的检查和构建：**\n",
        "    *   `__call__` 方法首先会检查这个模型/层是否已经构建了，这个检查一般是通过一个内部的标志位来实现的（例如 `self.built`）。\n",
        "    *   如果模型/层还没有构建（`self.built` 为 `False`），`__call__` 方法就会：\n",
        "        *   **推断输入形状：** 根据你传递给它的输入张量 `X`，推断出输入数据的形状，得到 `X.shape`。\n",
        "        *   **调用 `build` 方法：** 调用你定义的 `build` 方法，并将推断出的输入形状作为 `X_shape` 参数传递给 `build` 方法。\n",
        "        * **将 `self.built`设置为`True`**: 将模型内的`self.built`标志设置为`True`，表示此模型已经被构建。\n",
        "    *   如果模型/层已经构建（`self.built` 为 `True`），`__call__` 方法就会跳过构建步骤，直接进入下一步。\n",
        "\n",
        "3.  **执行 `call` 方法：**\n",
        "    *   无论模型/层是否需要构建，`__call__` 方法的最后一步都是调用你定义的 `call` 方法，并将输入张量 `X` 传递给 `call` 方法。\n",
        "    *   现在，因为已经确保模型/层是构建完成的，所以你的 `call` 方法可以安全地访问和使用模型的参数（`self.weight` 和 `self.bias`）。\n",
        "\n",
        "**总结：**\n",
        "\n",
        "*   **`tf.keras.Model` 的 `__call__` 方法是核心：**  它负责管理模型/层的生命周期，包括检查是否已构建，以及在需要时自动调用 `build` 方法。\n",
        "* **重写的是`call`**: 我们定义的`call`函数，是对tf.keras.Model父类中定义好的`__call__`方法所使用的函数体的重写。我们并没有直接重写`__call__`函数。\n",
        "*   **`build` 方法的自动执行：**  正是因为 `tf.keras.Model` 的 `__call__` 方法中的这些检查和调用机制，我们才能在第一次调用模型/层时，自动触发 `build` 方法的执行，而无需我们手动调用。\n",
        "*   **延迟初始化：**  这是一种延迟初始化的技术，参数的创建被推迟到了第一次需要使用这些参数的时候。\n",
        "\n",
        "**为什么要有这个机制？**\n",
        "\n",
        "这种自动构建机制极大地简化了模型/层的定义和使用。你不需要关心何时去调用 `build` 方法，`tf.keras.Model` 会帮你处理好这些细节。 你只需要写好 `__init__`，`build`和`call`这三个方法就可以了。"
      ],
      "metadata": {
        "id": "aMpNxWaHcyru"
      },
      "id": "aMpNxWaHcyru"
    },
    {
      "cell_type": "markdown",
      "id": "2f0293bd",
      "metadata": {
        "origin_pos": 24,
        "tab": [
          "tensorflow"
        ],
        "id": "2f0293bd"
      },
      "source": [
        "接下来，我们实例化`MyDense`类并访问其模型参数。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f684c7c1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:27:04.671422Z",
          "iopub.status.busy": "2023-08-18T07:27:04.670903Z",
          "iopub.status.idle": "2023-08-18T07:27:04.682086Z",
          "shell.execute_reply": "2023-08-18T07:27:04.681307Z"
        },
        "origin_pos": 29,
        "tab": [
          "tensorflow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f684c7c1",
        "outputId": "1cbd5f88-34f9-41b9-bc4c-a1ae21ae628c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.03281968, -0.00808049,  0.03600667],\n",
              "        [ 0.10606171,  0.0393287 , -0.04071729],\n",
              "        [ 0.07607688,  0.02219767,  0.07790767],\n",
              "        [-0.04000024, -0.02157551,  0.11163219],\n",
              "        [-0.03728421,  0.01720558, -0.03382197]], dtype=float32),\n",
              " array([0., 0., 0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dense = MyDense(3)\n",
        "dense(tf.random.uniform((2, 5)))\n",
        "dense.get_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a2073e",
      "metadata": {
        "origin_pos": 30,
        "id": "64a2073e"
      },
      "source": [
        "我们可以[**使用自定义层直接执行前向传播计算**]。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1adb5224",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:27:04.687142Z",
          "iopub.status.busy": "2023-08-18T07:27:04.686614Z",
          "iopub.status.idle": "2023-08-18T07:27:04.693146Z",
          "shell.execute_reply": "2023-08-18T07:27:04.692374Z"
        },
        "origin_pos": 33,
        "tab": [
          "tensorflow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1adb5224",
        "outputId": "027be2a4-d86b-488d-d3c7-ec679ead9474"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[0.08145942, 0.03432899, 0.06407103],\n",
              "       [0.10259131, 0.05410828, 0.05708903]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "dense(tf.random.uniform((2, 5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7414869f",
      "metadata": {
        "origin_pos": 35,
        "id": "7414869f"
      },
      "source": [
        "我们还可以(**使用自定义层构建模型**)，就像使用内置的全连接层一样使用自定义层。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dd6c81c8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:27:04.697912Z",
          "iopub.status.busy": "2023-08-18T07:27:04.697279Z",
          "iopub.status.idle": "2023-08-18T07:27:04.753499Z",
          "shell.execute_reply": "2023-08-18T07:27:04.752721Z"
        },
        "origin_pos": 38,
        "tab": [
          "tensorflow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd6c81c8",
        "outputId": "161f7594-b898-4feb-ee28-d715f9c037a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              "array([[0.00870765],\n",
              "       [0.        ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "net = tf.keras.models.Sequential([MyDense(8), MyDense(1)])\n",
        "net(tf.random.uniform((2, 64)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c58c0499",
      "metadata": {
        "origin_pos": 40,
        "id": "c58c0499"
      },
      "source": [
        "## 小结\n",
        "\n",
        "* 我们可以通过基本层类设计自定义层。这允许我们定义灵活的新层，其行为与深度学习框架中的任何现有层不同。\n",
        "* 在自定义层定义完成后，我们就可以在任意环境和网络架构中调用该自定义层。\n",
        "* 层可以有局部参数，这些参数可以通过内置函数创建。\n",
        "\n",
        "## 练习\n",
        "\n",
        "1. 设计一个接受输入并计算张量降维的层，它返回$y_k = \\sum_{i, j} W_{ijk} x_i x_j$。\n",
        "1. 设计一个返回输入数据的傅立叶系数前半部分的层。\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 练习 1\n",
        "class TensorReductionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # 输入形状: (batch_size, n)\n",
        "        n = input_shape[-1]\n",
        "        # 添加权重: (n, n, units)\n",
        "        self.W = self.add_weight(\n",
        "            name='W',\n",
        "            shape=(n, n, self.units),\n",
        "            initializer=tf.keras.initializers.GlorotNormal()\n",
        "        )\n",
        "\n",
        "    def call(self, X):\n",
        "        # 使用爱因斯坦求和替代循环\n",
        "        outer_product = tf.einsum(\"bi,bj->bij\", X, X)\n",
        "        y = tf.einsum(\"bij,ijk->bk\", outer_product, self.W)\n",
        "        return y"
      ],
      "metadata": {
        "id": "is3jhj1feBTU"
      },
      "id": "is3jhj1feBTU",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 练习 1 测试\n",
        "net = tf.keras.Sequential([TensorReductionLayer(4)])\n",
        "test_input = tf.random.uniform((2, 5))\n",
        "output = net(test_input)\n",
        "print(output.numpy)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5AKitGDhFEg",
        "outputId": "6e55fcf5-4ac4-4946-bee3-996e46dcd9b6"
      },
      "id": "c5AKitGDhFEg",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
            "array([[ 0.17281182,  0.2763521 ,  0.27563778, -0.05836287],\n",
            "       [ 0.08673773, -0.4523106 ,  0.6179464 , -0.21719313]],\n",
            "      dtype=float32)>>\n",
            "(2, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e46bc47",
      "metadata": {
        "origin_pos": 43,
        "tab": [
          "tensorflow"
        ],
        "id": "5e46bc47"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/1836)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}