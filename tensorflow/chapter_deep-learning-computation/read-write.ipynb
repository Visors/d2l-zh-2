{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Visors/d2l-zh-2/blob/main/tensorflow/chapter_deep-learning-computation/read-write.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77672097",
      "metadata": {
        "origin_pos": 0,
        "id": "77672097"
      },
      "source": [
        "# 读写文件\n",
        "\n",
        "到目前为止，我们讨论了如何处理数据，\n",
        "以及如何构建、训练和测试深度学习模型。\n",
        "然而，有时我们希望保存训练的模型，\n",
        "以备将来在各种环境中使用（比如在部署中进行预测）。\n",
        "此外，当运行一个耗时较长的训练过程时，\n",
        "最佳的做法是定期保存中间结果，\n",
        "以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。\n",
        "因此，现在是时候学习如何加载和存储权重向量和整个模型了。\n",
        "\n",
        "## (**加载和保存张量**)\n",
        "\n",
        "对于单个张量，我们可以直接调用`load`和`save`函数分别读写它们。\n",
        "这两个函数都要求我们提供一个名称，`save`要求将要保存的变量作为输入。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "69fac283",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:38:36.133599Z",
          "iopub.status.busy": "2023-08-18T07:38:36.133029Z",
          "iopub.status.idle": "2023-08-18T07:38:41.444409Z",
          "shell.execute_reply": "2023-08-18T07:38:41.443383Z"
        },
        "origin_pos": 3,
        "tab": [
          "tensorflow"
        ],
        "id": "69fac283"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.range(4)\n",
        "np.save('x-file.npy', x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "781e9c81",
      "metadata": {
        "origin_pos": 5,
        "id": "781e9c81"
      },
      "source": [
        "我们现在可以将存储在文件中的数据读回内存。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "27b3bcdc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:38:41.448996Z",
          "iopub.status.busy": "2023-08-18T07:38:41.448118Z",
          "iopub.status.idle": "2023-08-18T07:38:41.460061Z",
          "shell.execute_reply": "2023-08-18T07:38:41.459219Z"
        },
        "origin_pos": 8,
        "tab": [
          "tensorflow"
        ],
        "id": "27b3bcdc",
        "outputId": "b1b189b5-916b-4d1f-eaaa-d02ef812de0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "x2 = np.load('x-file.npy', allow_pickle=True)\n",
        "x2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63f53cc0",
      "metadata": {
        "origin_pos": 10,
        "id": "63f53cc0"
      },
      "source": [
        "我们可以[**存储一个张量列表，然后把它们读回内存。**]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f103aa5d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:38:41.463707Z",
          "iopub.status.busy": "2023-08-18T07:38:41.463165Z",
          "iopub.status.idle": "2023-08-18T07:38:41.470469Z",
          "shell.execute_reply": "2023-08-18T07:38:41.469682Z"
        },
        "origin_pos": 13,
        "tab": [
          "tensorflow"
        ],
        "id": "f103aa5d",
        "outputId": "84279bb1-3713-40d3-da0a-8a8b7b0af3e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 1., 2., 3.]), array([0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "y = tf.zeros(4)\n",
        "np.save('xy-files.npy', [x, y])\n",
        "x2, y2 = np.load('xy-files.npy', allow_pickle=True)\n",
        "(x2, y2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71a27e4b",
      "metadata": {
        "origin_pos": 15,
        "id": "71a27e4b"
      },
      "source": [
        "我们甚至可以(**写入或读取从字符串映射到张量的字典**)。\n",
        "当我们要读取或写入模型中的所有权重时，这很方便。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1444dd69",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:38:41.474176Z",
          "iopub.status.busy": "2023-08-18T07:38:41.473542Z",
          "iopub.status.idle": "2023-08-18T07:38:41.480252Z",
          "shell.execute_reply": "2023-08-18T07:38:41.479498Z"
        },
        "origin_pos": 18,
        "tab": [
          "tensorflow"
        ],
        "id": "1444dd69",
        "outputId": "b130bf1c-50f7-47ef-f78f-f51b13c70d95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array({'x': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 2, 3], dtype=int32)>, 'y': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>},\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "mydict = {'x': x, 'y': y}\n",
        "np.save('mydict.npy', mydict)\n",
        "mydict2 = np.load('mydict.npy', allow_pickle=True)\n",
        "'''\n",
        "mydict2 = np.load('mydict.npy')\n",
        "---------------------------------------------------------------------------\n",
        "ValueError                                Traceback (most recent call last)\n",
        "<ipython-input-5-2345116e4894> in <cell line: 0>()\n",
        "      2 np.save('mydict.npy', mydict)\n",
        "      3 # mydict2 = np.load('mydict.npy', allow_pickle=True)\n",
        "----> 4 mydict2 = np.load('mydict.npy')\n",
        "      5 mydict2\n",
        "\n",
        "1 frames\n",
        "/usr/local/lib/python3.11/dist-packages/numpy/lib/format.py in read_array(fp, allow_pickle, pickle_kwargs, max_header_size)\n",
        "    793         # The array contained Python objects. We need to unpickle the data.\n",
        "    794         if not allow_pickle:\n",
        "--> 795             raise ValueError(\"Object arrays cannot be loaded when \"\n",
        "    796                              \"allow_pickle=False\")\n",
        "    797         if pickle_kwargs is None:\n",
        "\n",
        "ValueError: Object arrays cannot be loaded when allow_pickle=False\n",
        "'''\n",
        "mydict2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd9cada",
      "metadata": {
        "origin_pos": 20,
        "id": "9fd9cada"
      },
      "source": [
        "## [**加载和保存模型参数**]\n",
        "\n",
        "保存单个权重向量（或其他张量）确实有用，\n",
        "但是如果我们想保存整个模型，并在以后加载它们，\n",
        "单独保存每个向量则会变得很麻烦。\n",
        "毕竟，我们可能有数百个参数散布在各处。\n",
        "因此，深度学习框架提供了内置函数来保存和加载整个网络。\n",
        "需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。\n",
        "例如，如果我们有一个3层多层感知机，我们需要单独指定架构。\n",
        "因为模型本身可以包含任意代码，所以模型本身难以序列化。\n",
        "因此，为了恢复模型，我们需要用代码生成架构，\n",
        "然后从磁盘加载参数。\n",
        "让我们从熟悉的多层感知机开始尝试一下。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fef50064",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:38:41.483840Z",
          "iopub.status.busy": "2023-08-18T07:38:41.483200Z",
          "iopub.status.idle": "2023-08-18T07:38:41.527917Z",
          "shell.execute_reply": "2023-08-18T07:38:41.527146Z"
        },
        "origin_pos": 23,
        "tab": [
          "tensorflow"
        ],
        "id": "fef50064"
      },
      "outputs": [],
      "source": [
        "# @tf.keras.utils.register_keras_serializable()\n",
        "# class MLP(tf.keras.Model):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.flatten = tf.keras.layers.Flatten()\n",
        "#         self.hidden = tf.keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
        "#         self.out = tf.keras.layers.Dense(units=10)\n",
        "\n",
        "#     # def build(self, input_shape):\n",
        "#     #     super().build(input_shape)\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         x = self.flatten(inputs)\n",
        "#         x = self.hidden(x)\n",
        "#         return self.out(x)\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class MLP(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):  # 接受父类参数\n",
        "        super().__init__(**kwargs)  # 传递父类参数\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.hidden = tf.keras.layers.Dense(units=256, activation=\"relu\")\n",
        "        self.out = tf.keras.layers.Dense(units=10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.flatten(inputs)\n",
        "        x = self.hidden(x)\n",
        "        return self.out(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        # 包含父类的配置（如 trainable, dtype 等）\n",
        "        config = super().get_config()\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        # 显式处理父类的配置\n",
        "        return cls(**config)\n",
        "\n",
        "net = MLP()\n",
        "X = tf.random.uniform((2, 20))\n",
        "Y = net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dfc39a6",
      "metadata": {
        "origin_pos": 25,
        "id": "3dfc39a6"
      },
      "source": [
        "接下来，我们[**将模型的参数存储在一个叫做“mlp.params”的文件中。**]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "49ae8009",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:38:41.531523Z",
          "iopub.status.busy": "2023-08-18T07:38:41.530898Z",
          "iopub.status.idle": "2023-08-18T07:38:41.540816Z",
          "shell.execute_reply": "2023-08-18T07:38:41.540069Z"
        },
        "origin_pos": 28,
        "tab": [
          "tensorflow"
        ],
        "id": "49ae8009",
        "outputId": "89bac72d-32f6-4dfd-af75-27031c0b97f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Variable path=mlp_6/dense_12/kernel, shape=(20, 256), dtype=float32, value=[[-0.07513162  0.05723687  0.05808729 ... -0.07338562 -0.0593318\n",
            "   0.12891558]\n",
            " [ 0.03308995  0.06979074  0.07231967 ...  0.09212859  0.05531348\n",
            "  -0.0923776 ]\n",
            " [-0.14568037 -0.12573588 -0.00111495 ... -0.05840454  0.02016944\n",
            "  -0.00835845]\n",
            " ...\n",
            " [ 0.12687671  0.05443908 -0.11200537 ...  0.08015789  0.07001048\n",
            "   0.12830433]\n",
            " [-0.07906099  0.00335337 -0.02530362 ... -0.00351118 -0.09068489\n",
            "  -0.0826921 ]\n",
            " [ 0.14097118 -0.13957466  0.09202006 ... -0.07460159  0.00472659\n",
            "  -0.02970877]]>, <Variable path=mlp_6/dense_12/bias, shape=(256,), dtype=float32, value=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]>, <Variable path=mlp_6/dense_13/kernel, shape=(256, 10), dtype=float32, value=[[-0.05393466  0.02173777  0.03520322 ...  0.11895862 -0.09658165\n",
            "  -0.08100704]\n",
            " [ 0.11097428 -0.07163151  0.01657976 ...  0.00036693  0.06265619\n",
            "   0.11714837]\n",
            " [-0.07249977 -0.14479068 -0.13775711 ...  0.10303026  0.04404478\n",
            "  -0.00394911]\n",
            " ...\n",
            " [-0.14230238  0.10323611 -0.07791957 ...  0.11631295  0.08530807\n",
            "   0.00229788]\n",
            " [-0.01601411 -0.14116019 -0.12605359 ...  0.14401218  0.13586757\n",
            "   0.05554399]\n",
            " [ 0.13268384 -0.08182836  0.12007129 ...  0.0751868  -0.07908103\n",
            "  -0.07455427]]>, <Variable path=mlp_6/dense_13/bias, shape=(10,), dtype=float32, value=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]>]\n"
          ]
        }
      ],
      "source": [
        "# net.save_weights('mlp.params')\n",
        "net.save_weights('mlp.weights.h5')\n",
        "print(net.weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "706b7bb4",
      "metadata": {
        "origin_pos": 30,
        "id": "706b7bb4"
      },
      "source": [
        "为了恢复模型，我们[**实例化了原始多层感知机模型的一个备份。**]\n",
        "这里我们不需要随机初始化模型参数，而是(**直接读取文件中存储的参数。**)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2928e5ed",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:38:41.544368Z",
          "iopub.status.busy": "2023-08-18T07:38:41.543752Z",
          "iopub.status.idle": "2023-08-18T07:38:41.553966Z",
          "shell.execute_reply": "2023-08-18T07:38:41.553233Z"
        },
        "origin_pos": 33,
        "tab": [
          "tensorflow"
        ],
        "id": "2928e5ed",
        "outputId": "0a90e561-e4d0-4e93-fb35-872de8cbe0df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Variable path=mlp_7/dense_14/kernel, shape=(20, 256), dtype=float32, value=[[-0.07513162  0.05723687  0.05808729 ... -0.07338562 -0.0593318\n",
            "   0.12891558]\n",
            " [ 0.03308995  0.06979074  0.07231967 ...  0.09212859  0.05531348\n",
            "  -0.0923776 ]\n",
            " [-0.14568037 -0.12573588 -0.00111495 ... -0.05840454  0.02016944\n",
            "  -0.00835845]\n",
            " ...\n",
            " [ 0.12687671  0.05443908 -0.11200537 ...  0.08015789  0.07001048\n",
            "   0.12830433]\n",
            " [-0.07906099  0.00335337 -0.02530362 ... -0.00351118 -0.09068489\n",
            "  -0.0826921 ]\n",
            " [ 0.14097118 -0.13957466  0.09202006 ... -0.07460159  0.00472659\n",
            "  -0.02970877]]>, <Variable path=mlp_7/dense_14/bias, shape=(256,), dtype=float32, value=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]>, <Variable path=mlp_7/dense_15/kernel, shape=(256, 10), dtype=float32, value=[[-0.05393466  0.02173777  0.03520322 ...  0.11895862 -0.09658165\n",
            "  -0.08100704]\n",
            " [ 0.11097428 -0.07163151  0.01657976 ...  0.00036693  0.06265619\n",
            "   0.11714837]\n",
            " [-0.07249977 -0.14479068 -0.13775711 ...  0.10303026  0.04404478\n",
            "  -0.00394911]\n",
            " ...\n",
            " [-0.14230238  0.10323611 -0.07791957 ...  0.11631295  0.08530807\n",
            "   0.00229788]\n",
            " [-0.01601411 -0.14116019 -0.12605359 ...  0.14401218  0.13586757\n",
            "   0.05554399]\n",
            " [ 0.13268384 -0.08182836  0.12007129 ...  0.0751868  -0.07908103\n",
            "  -0.07455427]]>, <Variable path=mlp_7/dense_15/bias, shape=(10,), dtype=float32, value=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]>]\n"
          ]
        }
      ],
      "source": [
        "clone = MLP()\n",
        "# clone.load_weights('mlp.params')\n",
        "X_clone = tf.random.uniform((2, 20))\n",
        "clone(X_clone)\n",
        "clone.load_weights('mlp.weights.h5')\n",
        "print(clone.weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "195b9596",
      "metadata": {
        "origin_pos": 35,
        "id": "195b9596"
      },
      "source": [
        "由于两个实例具有相同的模型参数，在输入相同的`X`时，\n",
        "两个实例的计算结果应该相同。\n",
        "让我们来验证一下。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "371d1a50",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:38:41.557592Z",
          "iopub.status.busy": "2023-08-18T07:38:41.556984Z",
          "iopub.status.idle": "2023-08-18T07:38:41.568425Z",
          "shell.execute_reply": "2023-08-18T07:38:41.567613Z"
        },
        "origin_pos": 38,
        "tab": [
          "tensorflow"
        ],
        "id": "371d1a50",
        "outputId": "9f59b66a-d3c8-479f-c6ce-51171e9cb983",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 10), dtype=bool, numpy=\n",
              "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True]])>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "Y_clone = clone(X)\n",
        "Y_clone == Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b425754",
      "metadata": {
        "origin_pos": 39,
        "id": "0b425754"
      },
      "source": [
        "## 小结\n",
        "\n",
        "* `save`和`load`函数可用于张量对象的文件读写。\n",
        "* 我们可以通过参数字典保存和加载网络的全部参数。\n",
        "* 保存架构必须在代码中完成，而不是在参数中完成。\n",
        "\n",
        "## 练习\n",
        "\n",
        "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
        "1. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？\n",
        "1. 如何同时保存网络架构和参数？需要对架构加上什么限制？\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "练习 1\n",
        "\n",
        "便于非代码工作者在更直观的可视化工具下分析模型。"
      ],
      "metadata": {
        "id": "OdPOlbvy1xn8"
      },
      "id": "OdPOlbvy1xn8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "练习 2\n",
        "\n",
        "可以读取存储的模型参数，将前两层写成块，在新网络中合适的位置加入该块结构。需要注意提取出来层应当是完整的拷贝而不是原来层的引用。"
      ],
      "metadata": {
        "id": "svr4wegH1_3X"
      },
      "id": "svr4wegH1_3X"
    },
    {
      "cell_type": "code",
      "source": [
        "# 练习 3\n",
        "net.save('net.keras')\n",
        "saved = tf.keras.models.load_model('net.keras')\n",
        "saved.summary()\n",
        "print(saved.weights)\n",
        "\n",
        "\n",
        "# '''\n",
        "# ---------------------------------------------------------------------------\n",
        "# TypeError                                 Traceback (most recent call last)\n",
        "# <ipython-input-11-eb1665006932> in <cell line: 0>()\n",
        "#       1 # 练习 3\n",
        "#       2 net.save('net.keras')\n",
        "# ----> 3 saved = tf.keras.models.load_model('net.keras')\n",
        "#       4 saved.summary()\n",
        "#       5 print(saved.weights)\n",
        "\n",
        "# 5 frames\n",
        "# /usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py in _retrieve_class_or_fn(name, registered_name, module, obj_type, full_config, custom_objects)\n",
        "#     801             return obj\n",
        "#     802\n",
        "# --> 803     raise TypeError(\n",
        "#     804         f\"Could not locate {obj_type} '{name}'. \"\n",
        "#     805         \"Make sure custom classes are decorated with \"\n",
        "\n",
        "# TypeError: Could not locate class 'MLP'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': None, 'class_name': 'MLP', 'config': {'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'MLP', 'build_config': {'input_shape': [2, 20]}}\n",
        "# '''"
      ],
      "metadata": {
        "id": "rfVTuLaK3S8G",
        "outputId": "669d3d58-b974-4b5b-9fec-084cdd95a442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "id": "rfVTuLaK3S8G",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m20\u001b[0m)                     │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    │           \u001b[38;5;34m5,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m10\u001b[0m)                     │           \u001b[38;5;34m2,570\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,946\u001b[0m (31.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,946</span> (31.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,946\u001b[0m (31.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,946</span> (31.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Variable path=dense_20/kernel, shape=(20, 256), dtype=float32, value=[[-0.07513162  0.05723687  0.05808729 ... -0.07338562 -0.0593318\n",
            "   0.12891558]\n",
            " [ 0.03308995  0.06979074  0.07231967 ...  0.09212859  0.05531348\n",
            "  -0.0923776 ]\n",
            " [-0.14568037 -0.12573588 -0.00111495 ... -0.05840454  0.02016944\n",
            "  -0.00835845]\n",
            " ...\n",
            " [ 0.12687671  0.05443908 -0.11200537 ...  0.08015789  0.07001048\n",
            "   0.12830433]\n",
            " [-0.07906099  0.00335337 -0.02530362 ... -0.00351118 -0.09068489\n",
            "  -0.0826921 ]\n",
            " [ 0.14097118 -0.13957466  0.09202006 ... -0.07460159  0.00472659\n",
            "  -0.02970877]]>, <Variable path=dense_20/bias, shape=(256,), dtype=float32, value=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]>, <Variable path=dense_21/kernel, shape=(256, 10), dtype=float32, value=[[-0.05393466  0.02173777  0.03520322 ...  0.11895862 -0.09658165\n",
            "  -0.08100704]\n",
            " [ 0.11097428 -0.07163151  0.01657976 ...  0.00036693  0.06265619\n",
            "   0.11714837]\n",
            " [-0.07249977 -0.14479068 -0.13775711 ...  0.10303026  0.04404478\n",
            "  -0.00394911]\n",
            " ...\n",
            " [-0.14230238  0.10323611 -0.07791957 ...  0.11631295  0.08530807\n",
            "   0.00229788]\n",
            " [-0.01601411 -0.14116019 -0.12605359 ...  0.14401218  0.13586757\n",
            "   0.05554399]\n",
            " [ 0.13268384 -0.08182836  0.12007129 ...  0.0751868  -0.07908103\n",
            "  -0.07455427]]>, <Variable path=dense_21/bias, shape=(10,), dtype=float32, value=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13a8373e",
      "metadata": {
        "origin_pos": 42,
        "tab": [
          "tensorflow"
        ],
        "id": "13a8373e"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/1838)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}