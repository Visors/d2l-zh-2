{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da3797f",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 线性回归的从零开始实现\n",
    ":label:`sec_linear_scratch`\n",
    "\n",
    "在了解线性回归的关键思想之后，我们可以开始通过代码来动手实现线性回归了。\n",
    "在这一节中，(**我们将从零开始实现整个方法，\n",
    "包括数据流水线、模型、损失函数和小批量随机梯度下降优化器**)。\n",
    "虽然现代的深度学习框架几乎可以自动化地进行所有这些工作，但从零开始实现可以确保我们真正知道自己在做什么。\n",
    "同时，了解更细致的工作原理将方便我们自定义模型、自定义层或自定义损失函数。\n",
    "在这一节中，我们将只使用张量和自动求导。\n",
    "在之后的章节中，我们会充分利用深度学习框架的优势，介绍更简洁的实现方式。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fbfcf4f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:09.446116Z",
     "iopub.status.busy": "2022-12-07T19:06:09.445449Z",
     "iopub.status.idle": "2022-12-07T19:06:12.122078Z",
     "shell.execute_reply": "2022-12-07T19:06:12.121278Z"
    },
    "origin_pos": 3,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:30:34.382842Z",
     "start_time": "2025-02-19T07:30:34.370433Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import tensorflow as tf\n",
    "# from d2l import tensorflow as d2l\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "91e4465a",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "## 生成数据集\n",
    "\n",
    "为了简单起见，我们将[**根据带有噪声的线性模型构造一个人造数据集。**]\n",
    "我们的任务是使用这个有限样本的数据集来恢复这个模型的参数。\n",
    "我们将使用低维数据，这样可以很容易地将其可视化。\n",
    "在下面的代码中，我们生成一个包含1000个样本的数据集，\n",
    "每个样本包含从标准正态分布中采样的2个特征。\n",
    "我们的合成数据集是一个矩阵$\\mathbf{X}\\in \\mathbb{R}^{1000 \\times 2}$。\n",
    "\n",
    "(**我们使用线性模型参数$\\mathbf{w} = [2, -3.4]^\\top$、$b = 4.2$\n",
    "和噪声项$\\epsilon$生成数据集及其标签：\n",
    "\n",
    "$$\\mathbf{y}= \\mathbf{X} \\mathbf{w} + b + \\mathbf\\epsilon.$$\n",
    "**)\n",
    "\n",
    "$\\epsilon$可以视为模型预测和标签时的潜在观测误差。\n",
    "在这里我们认为标准假设成立，即$\\epsilon$服从均值为0的正态分布。\n",
    "为了简化问题，我们将标准差设为0.01。\n",
    "下面的代码生成合成数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7da27e9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:12.125823Z",
     "iopub.status.busy": "2022-12-07T19:06:12.125399Z",
     "iopub.status.idle": "2022-12-07T19:06:12.131157Z",
     "shell.execute_reply": "2022-12-07T19:06:12.130415Z"
    },
    "origin_pos": 7,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:34:20.191142Z",
     "start_time": "2025-02-19T07:34:20.178861Z"
    }
   },
   "source": [
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"\n",
    "    生成y=Xw+b+噪声的合成数据集\n",
    "\n",
    "    参数:\n",
    "    w (tf.Tensor): 线性模型的真实权重向量\n",
    "    b (float): 线性模型的真实偏置项\n",
    "    num_examples (int): 要生成的样本数量\n",
    "\n",
    "    返回:\n",
    "    tuple: 包含特征矩阵 X 和标签向量 y 的元组\n",
    "    \"\"\"\n",
    "    # 创建一个形状为 (num_examples, w.shape[0]) 的零矩阵，用于存储特征\n",
    "    X = tf.zeros((num_examples, w.shape[0]))\n",
    "    # 向零矩阵 X 中添加从标准正态分布中采样得到的随机数，得到最终的特征矩阵\n",
    "    X += tf.random.normal(shape=X.shape)\n",
    "    # 根据线性模型公式 y = Xw + b 计算标签向量\n",
    "    # 先将权重向量 w 转换为列向量，再进行矩阵乘法，最后加上偏置项 b\n",
    "    y = tf.matmul(X, tf.reshape(w, (-1, 1))) + b\n",
    "    # 向计算得到的标签向量 y 中添加噪声，噪声服从均值为 0、标准差为 0.01 的正态分布\n",
    "    y += tf.random.normal(shape=y.shape, stddev=0.01)\n",
    "    # 将标签向量 y 转换为形状为 (-1, 1) 的列向量\n",
    "    y = tf.reshape(y, (-1, 1))\n",
    "    # 返回生成的特征矩阵 X 和标签向量 y\n",
    "    return X, y\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "147258f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:12.133982Z",
     "iopub.status.busy": "2022-12-07T19:06:12.133725Z",
     "iopub.status.idle": "2022-12-07T19:06:13.756079Z",
     "shell.execute_reply": "2022-12-07T19:06:13.755224Z"
    },
    "origin_pos": 8,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:34:26.642952Z",
     "start_time": "2025-02-19T07:34:26.630688Z"
    }
   },
   "source": [
    "true_w = tf.constant([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "10905b72",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "注意，[**`features`中的每一行都包含一个二维数据样本，\n",
    "`labels`中的每一行都包含一维标签值（一个标量）**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4cbb5d35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:13.759438Z",
     "iopub.status.busy": "2022-12-07T19:06:13.758997Z",
     "iopub.status.idle": "2022-12-07T19:06:13.765409Z",
     "shell.execute_reply": "2022-12-07T19:06:13.764676Z"
    },
    "origin_pos": 10,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:34:43.329976Z",
     "start_time": "2025-02-19T07:34:43.313639Z"
    }
   },
   "source": [
    "print('features:', features[0],'\\nlabel:', labels[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tf.Tensor([1.1639541  0.47367874], shape=(2,), dtype=float32) \n",
      "label: tf.Tensor([4.9196496], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "f0a414b1",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "通过生成第二个特征`features[:, 1]`和`labels`的散点图，\n",
    "可以直观观察到两者之间的线性关系。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f4d68bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:13.768616Z",
     "iopub.status.busy": "2022-12-07T19:06:13.768197Z",
     "iopub.status.idle": "2022-12-07T19:06:13.934798Z",
     "shell.execute_reply": "2022-12-07T19:06:13.933922Z"
    },
    "origin_pos": 12,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:36:54.530335Z",
     "start_time": "2025-02-19T07:36:54.325951Z"
    }
   },
   "source": [
    "# d2l.set_figsize()\n",
    "# d2l.plt.scatter(features[:, 1].numpy(), labels.numpy(), 1);\n",
    "\n",
    "# 设置图形大小\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# 绘制散点图\n",
    "plt.scatter(features[:, 1].numpy(), labels.numpy(), s=1)\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "38b11822",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "## 读取数据集\n",
    "\n",
    "回想一下，训练模型时要对数据集进行遍历，每次抽取一小批量样本，并使用它们来更新我们的模型。\n",
    "由于这个过程是训练机器学习算法的基础，所以有必要定义一个函数，\n",
    "该函数能打乱数据集中的样本并以小批量方式获取数据。\n",
    "\n",
    "在下面的代码中，我们[**定义一个`data_iter`函数，\n",
    "该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为`batch_size`的小批量**]。\n",
    "每个小批量包含一组特征和标签。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d6d2aaef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:13.939647Z",
     "iopub.status.busy": "2022-12-07T19:06:13.939376Z",
     "iopub.status.idle": "2022-12-07T19:06:13.944643Z",
     "shell.execute_reply": "2022-12-07T19:06:13.943857Z"
    },
    "origin_pos": 15,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:41:34.078692Z",
     "start_time": "2025-02-19T07:41:34.069924Z"
    }
   },
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    该函数用于生成小批量数据迭代器，用于模型训练时按批次获取数据。\n",
    "\n",
    "    参数:\n",
    "    batch_size (int): 每个小批量数据包含的样本数量。\n",
    "    features (tf.Tensor): 特征矩阵，包含所有样本的特征数据。\n",
    "    labels (tf.Tensor): 标签向量，包含所有样本对应的标签数据。\n",
    "\n",
    "    返回:\n",
    "    generator: 一个生成器，每次生成一个小批量的特征和对应的标签。\n",
    "    \"\"\"\n",
    "    # 获取特征矩阵的样本数量\n",
    "    num_examples = len(features)\n",
    "    # 生成从 0 到 num_examples - 1 的索引列表\n",
    "    indices = list(range(num_examples))\n",
    "    # 随机打乱索引列表，确保样本是随机读取的，没有特定顺序\n",
    "    random.shuffle(indices)\n",
    "    # 从 0 开始，以 batch_size 为步长遍历索引列表\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        # 截取当前批次的索引，确保不超出样本数量\n",
    "        j = tf.constant(indices[i: min(i + batch_size, num_examples)])\n",
    "        # 根据索引 j 从特征矩阵和标签向量中提取对应的数据，作为一个小批量返回\n",
    "        yield tf.gather(features, j), tf.gather(labels, j)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "f66371ed",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "通常，我们利用GPU并行运算的优势，处理合理大小的“小批量”。\n",
    "每个样本都可以并行地进行模型计算，且每个样本损失函数的梯度也可以被并行计算。\n",
    "GPU可以在处理几百个样本时，所花费的时间不比处理一个样本时多太多。\n",
    "\n",
    "我们直观感受一下小批量运算：读取第一个小批量数据样本并打印。\n",
    "每个批量的特征维度显示批量大小和输入特征数。\n",
    "同样的，批量的标签形状与`batch_size`相等。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d192a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:13.947820Z",
     "iopub.status.busy": "2022-12-07T19:06:13.947549Z",
     "iopub.status.idle": "2022-12-07T19:06:13.954014Z",
     "shell.execute_reply": "2022-12-07T19:06:13.953245Z"
    },
    "origin_pos": 17,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:42:14.505717Z",
     "start_time": "2025-02-19T07:42:14.488262Z"
    }
   },
   "source": [
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.0925233   0.39763045]\n",
      " [-0.14393705  0.78517973]\n",
      " [-0.62924176 -0.6870892 ]\n",
      " [-1.2073183   0.97474223]\n",
      " [-0.6155586  -0.78098464]\n",
      " [ 0.27051237 -0.9271898 ]\n",
      " [ 0.5878594   1.0880158 ]\n",
      " [-1.0177809   0.7463462 ]\n",
      " [-0.5619468   0.74079555]\n",
      " [ 0.9709181   0.6837292 ]], shape=(10, 2), dtype=float32) \n",
      " tf.Tensor(\n",
      "[[ 3.0292745 ]\n",
      " [ 1.2513304 ]\n",
      " [ 5.2655983 ]\n",
      " [-1.5109243 ]\n",
      " [ 5.6272216 ]\n",
      " [ 7.889416  ]\n",
      " [ 1.6634022 ]\n",
      " [-0.35836488]\n",
      " [ 0.56118757]\n",
      " [ 3.8071423 ]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "47df8058",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "当我们运行迭代时，我们会连续地获得不同的小批量，直至遍历完整个数据集。\n",
    "上面实现的迭代对教学来说很好，但它的执行效率很低，可能会在实际问题上陷入麻烦。\n",
    "例如，它要求我们将所有数据加载到内存中，并执行大量的随机内存访问。\n",
    "在深度学习框架中实现的内置迭代器效率要高得多，\n",
    "它可以处理存储在文件中的数据和数据流提供的数据。\n",
    "\n",
    "## 初始化模型参数\n",
    "\n",
    "[**在我们开始用小批量随机梯度下降优化我们的模型参数之前**]，\n",
    "(**我们需要先有一些参数**)。\n",
    "在下面的代码中，我们通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重，\n",
    "并将偏置初始化为0。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "24644bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:13.957112Z",
     "iopub.status.busy": "2022-12-07T19:06:13.956850Z",
     "iopub.status.idle": "2022-12-07T19:06:13.963249Z",
     "shell.execute_reply": "2022-12-07T19:06:13.962436Z"
    },
    "origin_pos": 21,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:43:02.554409Z",
     "start_time": "2025-02-19T07:43:02.536550Z"
    }
   },
   "source": [
    "w = tf.Variable(tf.random.normal(shape=(2, 1), mean=0, stddev=0.01),\n",
    "                trainable=True)\n",
    "b = tf.Variable(tf.zeros(1), trainable=True)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "3fc897f4",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "在初始化参数之后，我们的任务是更新这些参数，直到这些参数足够拟合我们的数据。\n",
    "每次更新都需要计算损失函数关于模型参数的梯度。\n",
    "有了这个梯度，我们就可以向减小损失的方向更新每个参数。\n",
    "因为手动计算梯度很枯燥而且容易出错，所以没有人会手动计算梯度。\n",
    "我们使用 :numref:`sec_autograd`中引入的自动微分来计算梯度。\n",
    "\n",
    "## 定义模型\n",
    "\n",
    "接下来，我们必须[**定义模型，将模型的输入和参数同模型的输出关联起来。**]\n",
    "回想一下，要计算线性模型的输出，\n",
    "我们只需计算输入特征$\\mathbf{X}$和模型权重$\\mathbf{w}$的矩阵-向量乘法后加上偏置$b$。\n",
    "注意，上面的$\\mathbf{Xw}$是一个向量，而$b$是一个标量。\n",
    "回想一下 :numref:`subsec_broadcasting`中描述的广播机制：\n",
    "当我们用一个向量加一个标量时，标量会被加到向量的每个分量上。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "111f5793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:13.966386Z",
     "iopub.status.busy": "2022-12-07T19:06:13.966125Z",
     "iopub.status.idle": "2022-12-07T19:06:13.970050Z",
     "shell.execute_reply": "2022-12-07T19:06:13.969301Z"
    },
    "origin_pos": 24,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:43:40.339907Z",
     "start_time": "2025-02-19T07:43:40.332450Z"
    }
   },
   "source": [
    "def linreg(X, w, b):  #@save\n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return tf.matmul(X, w) + b"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "bea7fe85",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "## [**定义损失函数**]\n",
    "\n",
    "因为需要计算损失函数的梯度，所以我们应该先定义损失函数。\n",
    "这里我们使用 :numref:`sec_linear_regression`中描述的平方损失函数。\n",
    "在实现中，我们需要将真实值`y`的形状转换为和预测值`y_hat`的形状相同。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0a3bdd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:13.973551Z",
     "iopub.status.busy": "2022-12-07T19:06:13.972937Z",
     "iopub.status.idle": "2022-12-07T19:06:13.976977Z",
     "shell.execute_reply": "2022-12-07T19:06:13.976248Z"
    },
    "origin_pos": 26,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:44:12.099469Z",
     "start_time": "2025-02-19T07:44:12.093208Z"
    }
   },
   "source": [
    "def squared_loss(y_hat, y):  #@save\n",
    "    \"\"\"均方损失\"\"\"\n",
    "    return (y_hat - tf.reshape(y, y_hat.shape)) ** 2 / 2"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "786bfe8b",
   "metadata": {
    "origin_pos": 27
   },
   "source": [
    "## (**定义优化算法**)\n",
    "\n",
    "正如我们在 :numref:`sec_linear_regression`中讨论的，线性回归有解析解。\n",
    "尽管线性回归有解析解，但本书中的其他模型却没有。\n",
    "这里我们介绍小批量随机梯度下降。\n",
    "\n",
    "在每一步中，使用从数据集中随机抽取的一个小批量，然后根据参数计算损失的梯度。\n",
    "接下来，朝着减少损失的方向更新我们的参数。\n",
    "下面的函数实现小批量随机梯度下降更新。\n",
    "该函数接受模型参数集合、学习速率和批量大小作为输入。每\n",
    "一步更新的大小由学习速率`lr`决定。\n",
    "<u>因为我们计算的损失是一个批量样本的总和，所以我们用批量大小（`batch_size`）\n",
    "来规范化步长，这样步长大小就不会取决于我们对批量大小的选择。</u>\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d5bf25ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:13.980164Z",
     "iopub.status.busy": "2022-12-07T19:06:13.979899Z",
     "iopub.status.idle": "2022-12-07T19:06:13.984079Z",
     "shell.execute_reply": "2022-12-07T19:06:13.983329Z"
    },
    "origin_pos": 30,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:45:06.329029Z",
     "start_time": "2025-02-19T07:45:06.321041Z"
    }
   },
   "source": [
    "def sgd(params, grads, lr, batch_size):  #@save\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    # 使用 zip 函数将参数列表 params 和梯度列表 grads 进行配对，然后遍历每一对参数和对应的梯度\n",
    "    for param, grad in zip(params, grads):\n",
    "        param.assign_sub(lr*grad/batch_size)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "deb2a49e",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "## 训练\n",
    "\n",
    "现在我们已经准备好了模型训练所有需要的要素，可以实现主要的[**训练过程**]部分了。\n",
    "理解这段代码至关重要，因为从事深度学习后，\n",
    "相同的训练过程几乎一遍又一遍地出现。\n",
    "在每次迭代中，我们读取一小批量训练样本，并通过我们的模型来获得一组预测。\n",
    "计算完损失后，我们开始反向传播，存储每个参数的梯度。\n",
    "最后，我们调用优化算法`sgd`来更新模型参数。\n",
    "\n",
    "概括一下，我们将执行以下循环：\n",
    "\n",
    "* 初始化参数\n",
    "* 重复以下训练，直到完成\n",
    "    * 计算梯度$\\mathbf{g} \\leftarrow \\partial_{(\\mathbf{w},b)} \\frac{1}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} l(\\mathbf{x}^{(i)}, y^{(i)}, \\mathbf{w}, b)$\n",
    "    * 更新参数$(\\mathbf{w}, b) \\leftarrow (\\mathbf{w}, b) - \\eta \\mathbf{g}$\n",
    "\n",
    "在每个*迭代周期*（epoch）中，我们使用`data_iter`函数遍历整个数据集，\n",
    "并将训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。\n",
    "这里的迭代周期个数`num_epochs`和学习率`lr`都是超参数，分别设为3和0.03。\n",
    "设置超参数很棘手，需要通过反复试验进行调整。\n",
    "我们现在忽略这些细节，以后会在 :numref:`chap_optimization`中详细介绍。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d03ddc4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:13.987146Z",
     "iopub.status.busy": "2022-12-07T19:06:13.986886Z",
     "iopub.status.idle": "2022-12-07T19:06:13.990586Z",
     "shell.execute_reply": "2022-12-07T19:06:13.989857Z"
    },
    "origin_pos": 33,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:47:41.265314Z",
     "start_time": "2025-02-19T07:47:41.256895Z"
    }
   },
   "source": [
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "7464d65f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:13.993579Z",
     "iopub.status.busy": "2022-12-07T19:06:13.993312Z",
     "iopub.status.idle": "2022-12-07T19:06:14.726399Z",
     "shell.execute_reply": "2022-12-07T19:06:14.725563Z"
    },
    "origin_pos": 36,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:47:45.726244Z",
     "start_time": "2025-02-19T07:47:43.675443Z"
    }
   },
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        with tf.GradientTape() as g:\n",
    "            l = loss(net(X, w, b), y)  # X和y的小批量损失\n",
    "        # 计算l关于[w,b]的梯度\n",
    "        dw, db = g.gradient(l, [w, b])\n",
    "        # 使用参数的梯度更新参数\n",
    "        sgd([w, b], [dw, db], lr, batch_size)\n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {float(tf.reduce_mean(train_l)):f}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.048240\n",
      "epoch 2, loss 0.000204\n",
      "epoch 3, loss 0.000049\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "a35395c1",
   "metadata": {
    "origin_pos": 38
   },
   "source": [
    "因为我们使用的是自己合成的数据集，所以我们知道真正的参数是什么。\n",
    "因此，我们可以通过[**比较真实参数和通过训练学到的参数来评估训练的成功程度**]。\n",
    "事实上，真实参数和通过训练学到的参数确实非常接近。\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "54455add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T19:06:14.729825Z",
     "iopub.status.busy": "2022-12-07T19:06:14.729285Z",
     "iopub.status.idle": "2022-12-07T19:06:14.734842Z",
     "shell.execute_reply": "2022-12-07T19:06:14.734074Z"
    },
    "origin_pos": 39,
    "tab": [
     "tensorflow"
    ],
    "ExecuteTime": {
     "end_time": "2025-02-19T07:47:53.481882Z",
     "start_time": "2025-02-19T07:47:53.469221Z"
    }
   },
   "source": [
    "print(f'w的估计误差: {true_w - tf.reshape(w, true_w.shape)}')\n",
    "print(f'b的估计误差: {true_b - b}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的估计误差: [ 0.00082195 -0.00049543]\n",
      "b的估计误差: [0.00012302]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "5b699baf",
   "metadata": {
    "origin_pos": 40
   },
   "source": [
    "注意，我们不应该想当然地认为我们能够完美地求解参数。\n",
    "在机器学习中，我们通常不太关心恢复真正的参数，而更关心如何高度准确预测参数。\n",
    "幸运的是，即使是在复杂的优化问题上，随机梯度下降通常也能找到非常好的解。\n",
    "其中一个原因是，在深度网络中存在许多参数组合能够实现高度精确的预测。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 我们学习了深度网络是如何实现和优化的。在这一过程中只使用张量和自动微分，不需要定义层或复杂的优化器。\n",
    "* 这一节只触及到了表面知识。在下面的部分中，我们将基于刚刚介绍的概念描述其他模型，并学习如何更简洁地实现其他模型。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 如果我们将权重初始化为零，会发生什么。算法仍然有效吗？\n",
    "1. 假设试图为电压和电流的关系建立一个模型。自动微分可以用来学习模型的参数吗?\n",
    "1. 能基于[普朗克定律](https://en.wikipedia.org/wiki/Planck%27s_law)使用光谱能量密度来确定物体的温度吗？\n",
    "1. 计算二阶导数时可能会遇到什么问题？这些问题可以如何解决？\n",
    "1. 为什么在`squared_loss`函数中需要使用`reshape`函数？\n",
    "1. 尝试使用不同的学习率，观察损失函数值下降的快慢。\n",
    "1. 如果样本个数不能被批量大小整除，`data_iter`函数的行为会有什么变化？\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. 训练的起点不同，算法仍然有效。\n",
    "2. 可以。理想状态下电压和电流是关于固定电阻的线性函数。\n",
    "3. 从普朗克定律可知，光谱能量密度 ($B_{\\lambda}(\\lambda, T)$) 是波长 ($\\lambda$) 和温度 ($T$) 的函数。如果已知光谱能量密度关于波长的分布，就可以预测物体的温度。\n",
    "4. 在计算二阶导数时，可能会遇到梯度消失或梯度爆炸的问题。梯度消失指的是在反向传播过程中，梯度值变得非常小，导致模型无法有效地学习。梯度爆炸指的是梯度值变得非常大，导致模型无法有效地学习。解决这些问题的方法包括使用梯度裁剪、使用更稳定的优化算法（如Adam）、使用正则化等。\n",
    "5. 在`squared_loss`函数中使用`reshape`函数是为了确保预测值和真实值的形状相同。这样可以避免在计算损失时出现形状不匹配的错误。"
   ],
   "id": "6f1c8eba7249cc25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T07:57:03.508783Z",
     "start_time": "2025-02-19T07:57:03.496477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 练习 6 预处理\n",
    "w = tf.Variable(tf.random.normal(shape=(2, 1), mean=0, stddev=0.01),\n",
    "                trainable=True)\n",
    "b = tf.Variable(tf.zeros(1), trainable=True)\n",
    "lr = 0.005\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss"
   ],
   "id": "12c86b98a56f4807",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T07:57:06.570614Z",
     "start_time": "2025-02-19T07:57:04.878822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 练习 6 训练\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        with tf.GradientTape() as g:\n",
    "            l = loss(net(X, w, b), y)  # X和y的小批量损失\n",
    "        # 计算l关于[w,b]的梯度\n",
    "        dw, db = g.gradient(l, [w, b])\n",
    "        # 使用参数的梯度更新参数\n",
    "        sgd([w, b], [dw, db], lr, batch_size)\n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {float(tf.reduce_mean(train_l)):f}')"
   ],
   "id": "b558c15e08847a0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 6.064819\n",
      "epoch 2, loss 2.338351\n",
      "epoch 3, loss 0.903893\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7. 会根据剩余个数切成一个更小的批次。",
   "id": "c2e5ee21b3da1a49"
  },
  {
   "cell_type": "markdown",
   "id": "3f7324b8",
   "metadata": {
    "origin_pos": 43,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1777)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
